{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile={'max_input_tokens': 128000, 'max_output_tokens': 16384, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True} client=<openai.resources.chat.completions.completions.Completions object at 0x122442530> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x12448d1e0> root_client=<openai.OpenAI object at 0x1224430a0> root_async_client=<openai.AsyncOpenAI object at 0x12448d120> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********') stream_usage=True\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response form LLM\n",
    "\n",
    "result=llm.invoke(\"What is capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a subset of artificial intelligence that focuses on creating new content or data that resembles existing data. This is achieved using models trained on large datasets to generate text, images, music, and other types of content. Some of the most well-known generative AI models include:\\n\\n1. **Generative Adversarial Networks (GANs)**: These models consist of two neural networks, a generator and a discriminator, that are trained together. The generator creates fake data, while the discriminator evaluates its authenticity. Through this adversarial process, the generator improves its ability to produce realistic data.\\n\\n2. **Variational Autoencoders (VAEs)**: These models encode input data into a compressed representation and then decode it back, learning to generate new, similar data in the process. VAEs are often used in generating images and other complex data forms.\\n\\n3. **Transformer-based Models**: Models like GPT (Generative Pre-trained Transformer) utilize large-scale transformer architectures to generate coherent text. They are trained on vast amounts of text data, enabling them to generate human-like text, complete prompts, or even engage in contextually aware conversations.\\n\\nGenerative AI has numerous applications, including content creation, enhancing creative processes, data augmentation, style transfer in art, and simulating realistic scenarios in virtual environments. Despite its potential, it also raises ethical considerations regarding copyright, misinformation, and privacy.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 280, 'prompt_tokens': 13, 'total_tokens': 293, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a0e9480a2f', 'id': 'chatcmpl-CteJZSVgKhIdD7DaavmEoITJ02HVh', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b8000-0cc1-76c3-9174-25e670385adb-0' usage_metadata={'input_tokens': 13, 'output_tokens': 280, 'total_tokens': 293, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Langsmith is a suite of tools and services designed to enhance the development and deployment of AI applications that utilize large language models (LLMs). Built by the creators of Langchain, a popular framework for building applications with LLMs, Langsmith offers features like monitoring, debugging, evaluating, and tracing to optimize the performance of language model applications. It acts as a bridge between the technical intricacies of language models and the practical needs of application development, helping developers streamline workflows, diagnose issues, and improve their AI-driven applications' overall effectiveness and reliability.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 110, 'prompt_tokens': 33, 'total_tokens': 143, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a0e9480a2f', 'id': 'chatcmpl-CtejjX3FQAmsAC1TWaYXSXcftEVft', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b8018-c676-7650-bc26-8a74d391a4a9-0' usage_metadata={'input_tokens': 33, 'output_tokens': 110, 'total_tokens': 143, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## chain \n",
    "chain = prompt_template | llm\n",
    "\n",
    "response = chain.invoke({\"input\": \"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a tool developed by LangChain that is designed to help developers build, monitor, and evaluate applications powered by large language models (LLMs). It provides several functionalities to streamline the development process of such applications. Key features of Langsmith include:\n",
      "\n",
      "1. **Integrated Development Tools**: It offers libraries that can be easily integrated into a developer's existing projects. These libraries help in setting up and managing applications driven by LLMs, making the development process more efficient.\n",
      "\n",
      "2. **Monitoring Capabilities**: Langsmith provides robust monitoring tools that allow developers to track the behavior and performance of their applications. This is essential for understanding how the application is interacting with users and how it is utilizing the LLM.\n",
      "\n",
      "3. **Evaluation Features**: The platform offers features to evaluate the effectiveness and accuracy of applications. This includes tools for testing different input scenarios and assessing how well the LLM fulfills its intended use cases.\n",
      "\n",
      "4. **Scalability and Testing**: Developers can use Langsmith to create scalable applications and conduct thorough testing to ensure reliability and performance under varying load conditions.\n",
      "\n",
      "Overall, Langsmith aims to make it easier for developers to leverage powerful language models in their applications while maintaining control and oversight over their performance and output.\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt_template | llm | output_parser\n",
    "\n",
    "response = chain.invoke({\"input\": \"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
